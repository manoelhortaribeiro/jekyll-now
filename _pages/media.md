---
layout: page
title: 
permalink: /media
---

- [Study of YouTube comments finds evidence of radicalization effect, **TechCrunch**][15]

- [Maybe It’s Not YouTube’s Algorithm That Radicalizes People, **WIRED**][12]

- [YouTube radicalization pipeline exists, study says, **NBC NEWS NOW**][5]

- [Study Shows How the ‘Intellectual Dark Web’ Is a Gateway to the Far Right, **Rolling Stone Magazine**][4]

- [YouTube may push users to more radical views over time, a new paper argues, **VICE**][7]

- [How YouTube can suck you into an extremist swamp, **Irish Times**][10] 

- [Radicalisation sur YouTube: des chercheurs soupçonnent l’algorithme, **Le Big Data** (in French)][9]

- [Radikalisierung durch YouTube? Großzahlige Studie zur Empfehlung rechtsextremer Inhalte, **netzpolitik.org** (in German)][8]

- [O Algoritmo da Ágora, **piauí** (in Portuguese)][14]

- [A parcialidade dos algoritmos, **Nexo Jornal** (in Portuguese)][13] 

- [Eine Plattform zwischen Hobby und Hass, **Deutschlandfunk** (in German)][11]

- [YouTube recommendation algorithm audit uncovers paths to radicalization, **VentureBeat**][6]

- [Chinese whispers 2.0, **WCSJ2019**][3]

- [Google premia estudos com foco no controle de fake news, **O Tempo** (in portuguese)][2]

- [Agora vai? Cientistas entram na caçada às notícias falsas e seus autores, **Notícias UOL** (in portuguese)][1]


[1]: https://web.archive.org/web/20190318181538/https://noticias.uol.com.br/tecnologia/noticias/redacao/2018/10/25/ficou-serio-cientistas-entram-na-briga-para-cacar-fake-news-e-seus-autores.htm

[2]: https://web.archive.org/web/20190318190702/https://www.otempo.com.br/capa/economia/google-premia-estudos-com-foco-no-controle-de-fake-news-1.2058878

[3]: https://web.archive.org/web/20190708120321/https://www.wcsj2019.eu/single-post/2019/07/05/Chinese-whispers-20

[4]: http://web.archive.org/web/20190908101310/https://www.rollingstone.com/culture/culture-news/youtube-far-right-radicalization-study-877061/

[5]: https://www.nbcnews.com/now/video/youtube-radicalization-pipeline-exists-study-says-68190277783

[6]: https://web.archive.org/web/20190908101708/https://venturebeat.com/2019/08/28/youtube-recommendation-algorithm-audit-uncovers-paths-to-radicalization/

[7]: https://web.archive.org/web/20190908101916/https://www.vice.com/en_ca/article/pa7pvb/what-79-million-youtube-comments-can-tell-us-about-far-right-radicalization

[8]: https://web.archive.org/web/20190908102212/https://netzpolitik.org/2019/radikalisierung-durch-youtube-grosszahlige-studie-zur-empfehlung-rechtsextremer-inhalte/

[9]: https://web.archive.org/web/20190908102356/https://www.lebigdata.fr/youtube-radicalisation-extreme

[10]: https://web.archive.org/web/20190911074432/https://www.irishtimes.com/opinion/una-mullally-how-youtube-can-suck-you-into-an-extremist-swamp-1.4011517

[11]: https://web.archive.org/save/https://www.deutschlandfunk.de/youtube-eine-plattform-zwischen-hobby-und-hass.724.de.html?dram:article_id=460659

[12]: https://web.archive.org/save/https://www.wired.com/story/not-youtubes-algorithm-radicalizes-people/

[13]: https://www.nexojornal.com.br/externo/2019/11/24/A-parcialidade-dos-algoritmos

[14]: https://piaui.folha.uol.com.br/materia/o-algoritmo-da-agora/

[15]: https://techcrunch.com/2020/01/28/study-of-youtube-comments-finds-evidence-of-radicalization-effect/